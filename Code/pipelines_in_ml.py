# -*- coding: utf-8 -*-
"""Pipelines in ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PY-l-iiR7JLvuZgKcDogrqOstBI9prZm
"""

from sklearn.pipeline import Pipeline
## feature scaling
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

steps = [("standard_scaler" , StandardScaler()) , ("classifier", LogisticRegression())]

print(steps)

pipe = Pipeline(steps)

## visualize_pipeline
from sklearn import set_config

set_config(display="diagram")

print(pipe)

# Creating a data set
from sklearn.datasets import make_classification
X, y = make_classification(n_samples=1000)

print(X.shape)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.33, random_state=42)

print(X_train)

pipe.fit(X_train , y_train)

y_pred = pipe.predict(X_test)

y_pred  # for Binary Classification

"""### Example 2
Displaying a pipeline with standard scaler, dimesnionality reduction and then estimator
"""

from sklearn.decomposition import PCA
from sklearn.svm import SVC

steps=[("scaling",StandardScaler()),
      ("PCA",PCA(n_components=3)),
      ("SVC",SVC())] ## Estimator to be used

pipe2=Pipeline(steps)
pipe2.fit(X_train,y_train)

pipe2.predict(X_test)

"""### Complex examples involving columns transformer"""

from sklearn.impute import SimpleImputer # for feature engineering or handling mssing values

## numerical processing pipeline
import numpy as np
numeric_processor=Pipeline(
    steps=[("imputation_mean",SimpleImputer(missing_values=np.nan,strategy="mean")),
          ("scaler",StandardScaler())]

)

print(numeric_processor)

##categorical procesing pipeline
from sklearn.preprocessing import OneHotEncoder
categorical_processor=Pipeline(
    steps=[("imputation_consatnt",SimpleImputer(fill_value="missing",strategy="constant")),
          ("onehot",OneHotEncoder(handle_unknown="ignore"))]

)

print(categorical_processor)

## combine processing technqiues
from sklearn.compose import ColumnTransformer

preprocessor=ColumnTransformer(
    [("categorical",categorical_processor,["gender","City"]),
    ("numerical",numeric_processor,["age","height"])]


)

print(preprocessor)

from sklearn.pipeline import make_pipeline
custom_pipe=make_pipeline(preprocessor,LogisticRegression())

print(custom_pipe)

custom_pipe.fit(X_train, y_train) # error because of absence of dataset with maeked column names like age gender and city

